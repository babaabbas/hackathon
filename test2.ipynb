{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"Provide your HUGGINGFACEHUB TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/hwchase17/chat-your-data/master/state_of_the_union.txt\"\n",
    "res = requests.get(url)\n",
    "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
    "  f.write(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Loader\n",
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader('./state_of_the_union.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Splitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Submitted by?\"\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And\n",
      "while you’re at it, pass the Disclose Act so Americans can know who is funding our elections.\n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an\n",
      "Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer,\n",
      "thank you for your service.\n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the\n",
      "United States Supreme Court.\n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our\n",
      "nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
     ]
    }
   ],
   "source": [
    "print(wrap_text_preserve_newlines(str(docs[0].page_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain_community.llms import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vamsh\\anaconda3\\envs\\AD3X\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\vamsh\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "llm=HuggingFaceEndpoint(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vamsh\\anaconda3\\envs\\AD3X\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" The President of the United States, Joe Biden, is calling on the Senate to pass three pieces of legislation: the Freedom to Vote Act, the John Lewis Voting Rights Act, and the Disclose Act. He also announced his nomination of Judge Ketanji Brown Jackson to the United States Supreme Court. The State of the Union is strong, and the country is making progress in areas such as veterans' benefits and cancer research. The President also addressed the situation in Ukraine, praising the courage of the Ukrainian people in the face of Russian aggression.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Submitted by?\"\n",
    "docs = db.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AWS Validator setup procedure.pdf',\n",
       " 'DigitalOcean Validator setup procedure.pdf',\n",
       " 'GCP Validator setup procedure.pdf',\n",
       " 'Vultr Validator setup procedure.pdf']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_folder_path = r'V:\\Vamshi\\Studies\\Hackathon_AD3X\\PDFs'\n",
    "os.listdir(pdf_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<langchain_community.document_loaders.unstructured.UnstructuredFileLoader at 0x160365692b0>,\n",
       " <langchain_community.document_loaders.unstructured.UnstructuredFileLoader at 0x16036569340>,\n",
       " <langchain_community.document_loaders.unstructured.UnstructuredFileLoader at 0x16036569430>,\n",
       " <langchain_community.document_loaders.unstructured.UnstructuredFileLoader at 0x16036568d40>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.unstructured import UnstructuredFileLoader\n",
    "\n",
    "pdf_folder_path = r'V:\\Vamshi\\Studies\\Hackathon_AD3X\\PDFs'\n",
    "\n",
    "loaders = [UnstructuredFileLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VectorstoreIndexCreator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mVectorstoreIndexCreator\u001b[49m(\n\u001b[0;32m      2\u001b[0m     embedding\u001b[38;5;241m=\u001b[39mHuggingFaceEmbeddings(),\n\u001b[0;32m      3\u001b[0m     text_splitter\u001b[38;5;241m=\u001b[39mCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mfrom_loaders(loaders)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VectorstoreIndexCreator' is not defined"
     ]
    }
   ],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    embedding=HuggingFaceEmbeddings(),\n",
    "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)).from_loaders(loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community.indexing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorstoreIndexCreator\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community.indexing'"
     ]
    }
   ],
   "source": [
    "from langchain_community.indexing import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Any', 'TYPE_CHECKING', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__getattr__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_module_lookup', 'faiss', 'importlib', 'utils']\n",
      "Help on package langchain_community.vectorstores in langchain_community:\n",
      "\n",
      "NAME\n",
      "    langchain_community.vectorstores - **Vector store** stores embedded data and performs vector search.\n",
      "\n",
      "DESCRIPTION\n",
      "    One of the most common ways to store and search over unstructured data is to\n",
      "    embed it and store the resulting embedding vectors, and then query the store\n",
      "    and retrieve the data that are 'most similar' to the embedded query.\n",
      "\n",
      "    **Class hierarchy:**\n",
      "\n",
      "    .. code-block::\n",
      "\n",
      "        VectorStore --> <name>  # Examples: Annoy, FAISS, Milvus\n",
      "\n",
      "        BaseRetriever --> VectorStoreRetriever --> <name>Retriever  # Example: VespaRetriever\n",
      "\n",
      "    **Main helpers:**\n",
      "\n",
      "    .. code-block::\n",
      "\n",
      "        Embeddings, Document\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    aerospike\n",
      "    alibabacloud_opensearch\n",
      "    analyticdb\n",
      "    annoy\n",
      "    apache_doris\n",
      "    astradb\n",
      "    atlas\n",
      "    awadb\n",
      "    azure_cosmos_db\n",
      "    azure_cosmos_db_no_sql\n",
      "    azuresearch\n",
      "    bagel\n",
      "    bageldb\n",
      "    baiducloud_vector_search\n",
      "    baiduvectordb\n",
      "    bigquery_vector_search\n",
      "    cassandra\n",
      "    chroma\n",
      "    clarifai\n",
      "    clickhouse\n",
      "    couchbase\n",
      "    dashvector\n",
      "    databricks_vector_search\n",
      "    deeplake\n",
      "    dingo\n",
      "    docarray (package)\n",
      "    documentdb\n",
      "    duckdb\n",
      "    ecloud_vector_search\n",
      "    elastic_vector_search\n",
      "    elasticsearch\n",
      "    epsilla\n",
      "    faiss\n",
      "    hanavector\n",
      "    hippo\n",
      "    hologres\n",
      "    infinispanvs\n",
      "    inmemory\n",
      "    jaguar\n",
      "    kdbai\n",
      "    kinetica\n",
      "    lancedb\n",
      "    lantern\n",
      "    llm_rails\n",
      "    manticore_search\n",
      "    marqo\n",
      "    matching_engine\n",
      "    meilisearch\n",
      "    milvus\n",
      "    momento_vector_index\n",
      "    mongodb_atlas\n",
      "    myscale\n",
      "    neo4j_vector\n",
      "    nucliadb\n",
      "    opensearch_vector_search\n",
      "    oraclevs\n",
      "    pathway\n",
      "    pgembedding\n",
      "    pgvecto_rs\n",
      "    pgvector\n",
      "    pinecone\n",
      "    qdrant\n",
      "    redis (package)\n",
      "    relyt\n",
      "    rocksetdb\n",
      "    scann\n",
      "    semadb\n",
      "    singlestoredb\n",
      "    sklearn\n",
      "    sqlitevss\n",
      "    starrocks\n",
      "    supabase\n",
      "    surrealdb\n",
      "    tair\n",
      "    tencentvectordb\n",
      "    thirdai_neuraldb\n",
      "    tidb_vector\n",
      "    tigris\n",
      "    tiledb\n",
      "    timescalevector\n",
      "    typesense\n",
      "    upstash\n",
      "    usearch\n",
      "    utils\n",
      "    vald\n",
      "    vdms\n",
      "    vearch\n",
      "    vectara\n",
      "    vespa\n",
      "    vikingdb\n",
      "    vlite\n",
      "    weaviate\n",
      "    xata\n",
      "    yellowbrick\n",
      "    zep\n",
      "    zep_cloud\n",
      "    zilliz\n",
      "\n",
      "FUNCTIONS\n",
      "    __getattr__(name: str) -> Any\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Aerospike', 'AlibabaCloudOpenSearch', 'AlibabaCloudOpenSea...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\vamsh\\anaconda3\\envs\\ad3x\\lib\\site-packages\\langchain_community\\vectorstores\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import langchain_community.vectorstores as unstructured\n",
    "\n",
    "print(dir(unstructured))\n",
    "\n",
    "help(unstructured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AD3X",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
